custom:
  basic-cluster-props: &basic-cluster-props
    spark_version: "9.1.x-cpu-ml-scala2.12"

  basic-static-cluster: &basic-static-cluster
    new_cluster:
      <<: *basic-cluster-props
      num_workers: 1
      node_type_id: "Standard_F4s"

  normal-cluster-props: &normal-cluster-props
    spark_version: "10.3.x-cpu-ml-scala2.12"

  normal-static-cluster: &normal-static-cluster
    new_cluster:
      <<: *normal-cluster-props
      num_workers: 2
      node_type_id: "Standard_E8_v3"

# please note that we're using FUSE reference for config file, hence we're going to load this file using its local FS path
environments:
  default:
    strict_path_adjustment_policy: true
    jobs:
      - name: "demo-ide-multiws-cicd-integration-test"
        <<:
          - *normal-static-cluster
        spark_python_task:
          python_file: "file://tests/integration/sample_test.py"
          parameters: ["--conf-file", "file:fuse://conf/test/sample.yml"]
  #environment should be declared in .dbx/project.json
  dev:
    strict_path_adjustment_policy: true
    jobs:
      - name: "demo-ide-multiws-cicd"
        <<:
          - *basic-static-cluster
        spark_python_task:
          python_file: "file://demo_covea_ide_gitinit/jobs/sample/entrypoint.py"
          parameters: ["--conf-file", "file:fuse://conf/test/sample.yml"]
      - name: "demo-ide-multiws-cicd-integration-test"
        <<:
          - *basic-static-cluster
        spark_python_task:
          python_file: "file://tests/integration/sample_test.py"
          parameters: ["--conf-file", "file:fuse://conf/test/sample.yml"]
  #environment should be declared in .dbx/project.json (json's profile var's irrelevant for this env)
  staging:
    strict_path_adjustment_policy: true
    jobs:
      - name: "demo-ide-multiws-cicd-integration-test"
        <<:
          - *normal-static-cluster
        spark_python_task:
          python_file: "file://tests/integration/sample_test.py"
          parameters: ["--conf-file", "file:fuse://conf/test/sample.yml"]
  #environment should be declared in .dbx/project.json (json's profile var's irrelevant for this env)
  prod:
    strict_path_adjustment_policy: true
    jobs:
      - name: "demo-ide-multiws-cicd"
        <<:
          - *normal-static-cluster
        spark_python_task:
          python_file: "file://demo_covea_ide_gitinit/jobs/sample/entrypoint.py"
          parameters: ["--conf-file", "file:fuse://conf/test/sample.yml"]
        schedule:
          quartz_cron_expression: "0 45 7 ? * * *"
          timezone_id: "Europe/London"